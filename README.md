## DetectMe Project

This project focuses on detecting AI-generated faces versus real photos. The codebase is structured to preprocess images, train a machine learning model, and evaluate its performance.

---

### **Project Structure**

```
003 DetectMe/
├── dataset/                 # Directory for storing images
│   ├── ai_generated_faces/ # AI-generated faces
│   └── real_photos/        # Real photos
├── output/                  # Directory for processed data and results
├── Create_Folders.py        # Initializes dataset folder structure
├── Load_Images.py           # Preprocesses images into .npy format
├── split_dataset.py         # Splits data into train and test sets
├── train_model.py           # Builds and trains the model
├── evaluate_model.py        # Evaluates the trained model
├── requirements.txt         # Python dependencies
├── .gitignore               # Excludes unnecessary files from version control
└── README.md                # Project documentation
```

---

### **Steps to Run the Scripts**

#### **1. Set Up Virtual Environment**

```bash
python3 -m venv venv
source venv/bin/activate  
```

#### **2. Install Dependencies**

```bash
pip install -r requirements.txt
```

#### **3. Initialize Dataset Folders**

Run `Create_Folders.py` to create the folder structure:

```bash
python3 Create_Folders.py
```

#### **4. Add Images to Dataset**

- Place real photos in `dataset/real_photos/`
- Place AI-generated images in `dataset/ai_generated_faces/`

#### **5. Preprocess Images**

Run `Load_Images.py` to preprocess images and save them as `.npy` files:

```bash
python3 Load_Images.py
```

#### **6. Split Dataset**

Run `split_dataset.py` to split the dataset into training and testing sets:

```bash
python3 split_dataset.py
```

#### **7. Train the Model**

Run `train_model.py` to train the AI detection model:

```bash
python3 train_model.py
```

#### **8. Evaluate the Model**

Run `evaluate_model.py` to evaluate the model's accuracy on the test set:

```bash
python3 evaluate_model.py
```

Results such as evaluation metrics and sample predictions will be saved in the `output/` directory:
- **Evaluation Results**: `output/evaluation_results.png`
- **Sample Predictions**: `output/sample_predictions.png`

---

### **Example Results**

#### **Training Results**

After training the model, you should see logs showing the model’s accuracy and loss:

```plaintext
Epoch 10/10
16/16 [==============================] - 2s 123ms/step - loss: 0.5432 - accuracy: 0.8125
Model saved as: output/ai_face_detector.h5
```

#### **Evaluation Results**

When evaluating the model, you should see metrics like accuracy and a classification report:

```plaintext
Test Accuracy: 75.00%

Classification Report:
              precision    recall  f1-score   support

  Real Photo       1.00      0.50      0.67         4
AI-Generated       0.67      1.00      0.80         4

    accuracy                           0.75         8
   macro avg       0.83      0.75      0.73         8
weighted avg       0.83      0.75      0.73         8
```

#### **Saved Results**

- **Evaluation Results**: `output/evaluation_results.png`
- **Sample Predictions**: `output/sample_predictions.png`

---

### **Reflect and Analyze**

#### **Overall Learning Experience**
Working with AI to create this program has been a rewarding experience, offering insights into both the power and challenges of machine learning. One of the most significant successes was the ability to train a model that could identify AI-generated images with a reasonable accuracy of 75%. However, challenges such as managing a limited dataset and handling edge cases highlighted the importance of data diversity and model robustness. This project underscored the value of feature analysis, like detecting symmetry and artifacts, and revealed areas for improvement, such as leveraging advanced architectures and forensic techniques. Overall, it demonstrated the exciting potential of AI in content verification while emphasizing the need for continuous refinement.

#### **Program Performance**
- The program achieved an accuracy of **75%** on the test dataset, correctly classifying most examples.
- However, some misclassifications occurred, particularly with real photos being classified as AI-generated. This may indicate that certain real photo features resemble those often generated by AI.

#### **Feature Analysis**
- The program analyzed features such as:
  - **Symmetry**: AI-generated images often display near-perfect facial symmetry.
  - **Coherence**: Real images typically have consistent and natural facial features.
  - **Artifacts**: Blurry backgrounds or unnatural textures are common in AI-generated images.
- These aspects were useful as they highlight common discrepancies between real and AI-generated media, though edge cases (highly symmetrical real photos) remain challenging.

#### **Limitations and Improvements**
- **Limitations:**
  - The dataset size was limited, which likely affected the model’s generalization ability.
  - The program struggles with edge cases, such as real photos that share traits with AI-generated images.
  - Artifacts like lighting inconsistencies or subtle distortions were not fully leveraged.

- **Improvements:**
  - Expand the dataset to include more diverse real and AI-generated images.
  - Introduce data augmentation (rotations, flips) to improve model robustness.
  - Use advanced architectures (ResNet, EfficientNet) for better feature extraction.
  - Incorporate additional forensic techniques, such as noise analysis or GAN fingerprint detection, to further differentiate images.

---
